{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How To Train Model for Open Book Q&A Technique\nIn this notebook we demonstrate how to train a model to be used with top scoring Open Book Q&A method. The Open Book method was first presented by JJ (@jjinho) [here][1], then Quangteo (@quangbk) improved RAM usage [here][2], and Anil (@nlztrk) combined with Q&A [here][3]. Radek (@radek1) demonstrated the strength of Q&A [here][5]. Next Mgoksu (@mgoksu) demonstrated how to achieve top public LB=0.807 using this method [here][4] by finetuning DeBerta large on this method.\n\nIn order to train a model for use with Open Book Q&A, we need a CSV that contains; `prompt` (i.e. question), `A, B, C, D, E` (i.e. answer choices), and we need a column of `context` extracted from wikipedia pages for each question. To generate the `context` column, we run Mgoksu's notebook [here][4]. In code cell #5, we load our CSV without `context` column with code `trn = pd.read_csv(OUR_DATASET.CSV)`. Then in code cell #21 our dataset is saved to disk as `test_context.csv` with the column `context` added.\n\nI have searched and concatenated all publicly shared datasets into one 60k CSV and then ran Mgoksu's notebook with `NUM_TITLES_INCLUDE = 5` and `NUM_SENTENCES_INCLUDE = 20`. This added an additional `context` column. I uploaded the resultant CSV file to a Kaggle dataset [here][6]. If you enjoy the notebook you are reading, please upvote the dataset too. Thanks! \n\n![](https://miro.medium.com/v2/resize:fit:800/format:webp/1*bTGY3fKIgNefQxNsOYpnBw.png)\n \n(image source [here][7])\n\n[1]: https://www.kaggle.com/code/jjinho/open-book-llm-science-exam\n[2]: https://www.kaggle.com/code/quangbk/open-book-llm-science-exam-reduced-ram-usage\n[3]: https://www.kaggle.com/code/nlztrk/openbook-debertav3-large-baseline-single-model\n[4]: https://www.kaggle.com/code/mgoksu/0-807-sharing-my-trained-with-context-model\n[5]: https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training\n[6]: https://www.kaggle.com/datasets/cdeotte/60k-data-with-context-v2\n[7]: https://blog.gopenai.com/enrich-llms-with-retrieval-augmented-generation-rag-17b82a96b6f0","metadata":{}},{"cell_type":"markdown","source":"# Load CSV\nWe will load 60k CSV of `prompts`, `A,B,C,D,E`, and `context` from my Kaggle dataset [here][1]. This dataset is all publicly shared datasets concatenated then processed with Mgoksu's notebook [here][2] to create a `context` column. (To learn more about the datasets within read my discussion post). This Kaggle dataset also contains competition `train.csv` with added `context` column (to be used as a validation dataset).\n\nIn this train notebook, we have internet turned on and can choose whatever model we wish to download and train. After we finetune this model, we will create a second notebook with the Open Book Q&A technique and load the finetuned model from the output of this notebook. The second notebook will have internet turned off so that it can be submitted to Kaggle's competition.\n\n[1]: https://www.kaggle.com/datasets/cdeotte/60k-data-with-context-v2\n[2]: https://www.kaggle.com/code/mgoksu/0-807-sharing-my-trained-with-context-model","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"  # 指定CUDA设备ID，用于确定哪些GPU可用于计算\n\nfrom typing import Optional, Union\nimport pandas as pd, numpy as np, torch  # 导入必要的库\nfrom datasets import Dataset  # 从datasets库中导入Dataset类\nfrom dataclasses import dataclass  # 导入dataclass装饰器\nfrom transformers import AutoTokenizer  # 从transformers库中导入AutoTokenizer类\nfrom transformers import EarlyStoppingCallback  # 导入EarlyStoppingCallback类，用于提前停止训练\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy  # 导入预训练分词器基类和填充策略枚举类\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer  # 导入多项选择自动模型类、训练参数类和训练器类\n\nVER=2  # 定义版本变量\n# 使用60K的子集进行训练\nNUM_TRAIN_SAMPLES = 1_024  # 定义训练样本数量\n# 参数高效微调（Parameter Efficient Fine Tuning，PEFT）\n# PEFT要求使用1个XP100 GPU而不是2个T4\nUSE_PEFT = False  # 定义是否使用PEFT的布尔变量\n# 冻结的层数\n# DeBERTa大模型总共有24层\nFREEZE_LAYERS = 18  # 定义要冻结的层数\n# 是否冻结嵌入\nFREEZE_EMBEDDINGS = True  # 定义是否冻结嵌入的布尔变量\n# 上下文、问题和答案的最大输入长度\nMAX_INPUT = 256  # 定义最大输入长度\n# Hugging Face模型\nMODEL = 'microsoft/deberta-v3-large'  # 定义使用的模型","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:40:22.855891Z","iopub.execute_input":"2023-09-02T02:40:22.856518Z","iopub.status.idle":"2023-09-02T02:40:37.996876Z","shell.execute_reply.started":"2023-09-02T02:40:22.856462Z","shell.execute_reply":"2023-09-02T02:40:37.995876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#验证集使用的是比赛提供的200条数据\ndf_valid = pd.read_csv('/kaggle/input/60k-data-with-context-v2/train_with_context2.csv')\nprint('Validation data size:', df_valid.shape )\ndf_valid.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:40:37.998914Z","iopub.execute_input":"2023-09-02T02:40:37.9993Z","iopub.status.idle":"2023-09-02T02:40:38.063925Z","shell.execute_reply.started":"2023-09-02T02:40:37.999265Z","shell.execute_reply":"2023-09-02T02:40:38.062638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#训练集\ndf_train = pd.read_csv('/kaggle/input/60k-data-with-context-v2/all_12_with_context2.csv')\ndf_train = df_train.drop(columns=\"source\")\ndf_train = df_train.fillna('').sample(NUM_TRAIN_SAMPLES)\nprint('Train data size:', df_train.shape )\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:40:38.067211Z","iopub.execute_input":"2023-09-02T02:40:38.067881Z","iopub.status.idle":"2023-09-02T02:40:45.660139Z","shell.execute_reply.started":"2023-09-02T02:40:38.06785Z","shell.execute_reply":"2023-09-02T02:40:45.659097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader\nCode is from Radek's notebook [here][1] with modifications to the tokenization process.\n\n[1]: https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training","metadata":{}},{"cell_type":"code","source":"# 数据整理\noption_to_index = {option: idx for idx, option in enumerate('ABCDE')}  # 创建选项到索引的映射，例如：{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\nindex_to_option = {v: k for k,v in option_to_index.items()}  # 创建索引到选项的映射，例如：{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n\n# 预处理函数\ndef preprocess(example):\n    # 为每个选项创建第一句，即上下文，并重复5次（因为有5个选项）\n    first_sentence = [\"[CLS] \" + example['context']] * 5  \n    # 为每个选项创建第二句，包括提示、选项和特殊的分隔符\n    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']  \n    # 使用分词器对句子进行分词，并限制最大长度\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n                                  max_length=MAX_INPUT, add_special_tokens=False)\n    # 将正确答案的选项映射到索引\n    tokenized_example['label'] = option_to_index[example['answer']]  \n    return tokenized_example  # 返回分词后的例子\n\n# 用于多项选择任务的数据整理类\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase  # 预训练的分词器\n    padding: Union[bool, str, PaddingStrategy] = True  # 填充策略\n    max_length: Optional[int] = None  # 最大长度\n    pad_to_multiple_of: Optional[int] = None  # 填充到指定的倍数\n    \n    # 调用方法，用于整理一批特征\n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'  # 确定标签的键名\n        labels = [feature.pop(label_name) for feature in features]  # 提取并移除标签\n        batch_size = len(features)  # 批次大小\n        num_choices = len(features[0]['input_ids'])  # 选项数量\n        # 将特征展平，以便每个选项都有一个单独的特征字典\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])  # 展平特征列表\n        \n        # 使用分词器的pad方法进行填充，并将结果转换为张量\n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        # 调整张量的形状以匹配批次大小和选项数量\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}  \n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)  # 添加标签张量\n        return batch  # 返回整理后的批次","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:40:45.662616Z","iopub.execute_input":"2023-09-02T02:40:45.663363Z","iopub.status.idle":"2023-09-02T02:40:45.687767Z","shell.execute_reply.started":"2023-09-02T02:40:45.663325Z","shell.execute_reply":"2023-09-02T02:40:45.68666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL)\ndataset_valid = Dataset.from_pandas(df_valid)\ndataset = Dataset.from_pandas(df_train)\ndataset = dataset.remove_columns([\"__index_level_0__\"])\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:40:45.68961Z","iopub.execute_input":"2023-09-02T02:40:45.690601Z","iopub.status.idle":"2023-09-02T02:40:47.780638Z","shell.execute_reply.started":"2023-09-02T02:40:45.690562Z","shell.execute_reply":"2023-09-02T02:40:47.779712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset_valid = dataset_valid.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_dataset = dataset.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:40:47.782298Z","iopub.execute_input":"2023-09-02T02:40:47.783225Z","iopub.status.idle":"2023-09-02T02:41:14.602319Z","shell.execute_reply.started":"2023-09-02T02:40:47.783191Z","shell.execute_reply":"2023-09-02T02:41:14.601259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 构建模型\n# 我们将使用Hugging Face的AutoModelForMultipleChoice。关于可能的模型列表，请参阅Hugging Face的仓库[此处][1]。\n# 我们可以选择使用PEFT来加速训练并减少内存使用，但是我注意到验证准确率较低。（注意，PEFT要求我们使用1xP100而不是2xT4 GPU，我不确定为什么）。\n# 我们还可以选择冻结层，这也会加速训练并减少内存使用，但是验证准确率可能会降低。\n# [1]: https://huggingface.co/models","metadata":{}},{"cell_type":"code","source":"# 构建模型\nmodel = AutoModelForMultipleChoice.from_pretrained(MODEL)  # 从预训练模型加载AutoModelForMultipleChoice模型，是Hugging Face的Transformers库中的一个类，它是为解决多项选择任务而设计的\n\n# 参数高效微调方法，会损害模型的性能，在GPU允许的情况下能不开启就不开启\nif USE_PEFT:\n    !pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl  \n    print('We are using PEFT.')\n    from peft import LoraConfig, get_peft_model, TaskType  # 导入PEFT相关的类和函数\n    # 配置PEFT参数\n    peft_config = LoraConfig(\n        r=8, lora_alpha=4, task_type=TaskType.SEQ_CLS, lora_dropout=0.1, \n        bias=\"none\", inference_mode=False, \n        target_modules=[\"query_proj\", \"value_proj\"],\n        modules_to_save=['classifier','pooler'],\n    )\n    # 获取经过PEFT处理的模型\n    model = get_peft_model(model, peft_config)  \n    model.print_trainable_parameters()  # 打印可训练的参数\n\n# 如果需要，冻结模型的嵌入层\nif FREEZE_EMBEDDINGS:\n    print('Freezing embeddings.')\n    for param in model.deberta.embeddings.parameters():  # 遍历嵌入层的所有参数\n        param.requires_grad = False  # 禁止对参数的梯度计算，从而冻结嵌入层\n\n# 如果需要，冻结模型的指定层数\nif FREEZE_LAYERS > 0:\n    print(f'Freezing {FREEZE_LAYERS} layers.')\n    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:  # 遍历要冻结的层\n        for param in layer.parameters():  # 遍历层中的所有参数\n            param.requires_grad = False  # 禁止对参数的梯度计算，从而冻结层\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MAP@3 Metric\nThe competition metric is MAP@3 therefore we will make a custom code to add to Hugging Face's trainer. Discussion [here][1]\n\n[1]: https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/435602","metadata":{}},{"cell_type":"code","source":"# 评价指标\ndef map_at_3(predictions, labels):\n    map_sum = 0  # 初始化平均准确率的总和为0\n    pred = np.argsort(-1 * np.array(predictions), axis=1)[:, :3]  # 对预测结果按照降序排列，并取前3个最可能的预测\n    for x, y in zip(pred, labels):  # 遍历预测和实际标签\n        # 对于每个预测，如果预测与实际标签匹配，则其值为1/排名，否则为0\n        z = [1 / i if y == j else 0 for i, j in zip([1, 2, 3], x)]  \n        map_sum += np.sum(z)  # 累计每个预测的准确率\n    return map_sum / len(predictions)  # 返回平均准确率\n\ndef compute_metrics(p):\n    predictions = p.predictions.tolist()  # 将预测结果转换为列表\n    labels = p.label_ids.tolist()  # 将实际标签转换为列表\n    return {\"map@3\": map_at_3(predictions, labels)}  # 返回包含map@3评价指标的字典","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:41:24.305562Z","iopub.execute_input":"2023-09-02T02:41:24.306294Z","iopub.status.idle":"2023-09-02T02:41:24.314946Z","shell.execute_reply.started":"2023-09-02T02:41:24.306255Z","shell.execute_reply":"2023-09-02T02:41:24.313738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 训练参数\ntraining_args = TrainingArguments(\n    warmup_ratio=0.1,  # 预热率，用于学习率调度，预热期间学习率将线性增加\n    learning_rate=2e-5,  # 学习率\n    per_device_train_batch_size=1,  # 每个设备上的训练批次大小\n    per_device_eval_batch_size=2,  # 每个设备上的评估批次大小\n    num_train_epochs=2,  # 训练周期数\n    report_to='none',  # 不报告到任何平台\n    output_dir=f'./checkpoints_{VER}',  # 输出目录，用于保存模型和日志\n    overwrite_output_dir=True,  # 如果输出目录已存在，是否覆盖\n    fp16=True,  # 使用16位浮点数进行训练，以节省内存和提高速度\n    gradient_accumulation_steps=8,  # 梯度累积步数，用于处理大批次\n    logging_steps=25,  # 日志记录步数，每25步记录一次日志\n    evaluation_strategy='steps',  # 评估策略，按步数进行评估\n    eval_steps=25,  # 评估步数，每25步进行一次评估\n    save_strategy=\"steps\",  # 保存策略，按步数保存模型\n    save_steps=25,  # 保存步数，每25步保存一次模型\n    load_best_model_at_end=False,  # 在训练结束时不加载最佳模型\n    metric_for_best_model='map@3',  # 用于选择最佳模型的指标\n    lr_scheduler_type='cosine',  # 学习率调度类型，使用余弦退火调度\n    weight_decay=0.01,  # 权重衰减\n    save_total_limit=2,  # 保存的总模型限制，最多保存2个模型\n)\n# 创建训练器\ntrainer = Trainer(\n    model=model,  # 要训练的模型\n    args=training_args,  # 训练参数\n    tokenizer=tokenizer,  # 用于分词的分词器\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),  # 用于处理数据的数据整理器\n    train_dataset=tokenized_dataset,  # 训练数据集\n    eval_dataset=tokenized_dataset_valid,  # 评估数据集\n    compute_metrics=compute_metrics,  # 用于计算评价指标的函数\n    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],  # 早停回调，此行已注释，可根据需要取消注释\n)\n\n# 开始训练\ntrainer.train()\n# 保存模型\ntrainer.save_model(f'model_v{VER}')  # 保存模型到指定路径","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:41:24.316629Z","iopub.execute_input":"2023-09-02T02:41:24.317374Z","iopub.status.idle":"2023-09-02T02:41:24.398982Z","shell.execute_reply.started":"2023-09-02T02:41:24.317335Z","shell.execute_reply":"2023-09-02T02:41:24.397829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Verify Saved Model\nDuring training, we see the MAP@3 validation score above. Let's load the saved model and compute it again here to verify that our model is saved correctly.","metadata":{}},{"cell_type":"code","source":"del model, trainer\nif USE_PEFT:\n    model = AutoModelForMultipleChoice.from_pretrained(MODEL)\n    model = get_peft_model(model, peft_config)\n    checkpoint = torch.load(f'model_v{VER}/pytorch_model.bin')\n    model.load_state_dict(checkpoint)\nelse:\n    model = AutoModelForMultipleChoice.from_pretrained(f'model_v{VER}')\ntrainer = Trainer(model=model)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:42:35.053535Z","iopub.status.idle":"2023-09-02T02:42:35.054036Z","shell.execute_reply.started":"2023-09-02T02:42:35.053782Z","shell.execute_reply":"2023-09-02T02:42:35.053806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/60k-data-with-context-v2/train_with_context2.csv')\ntokenized_test_dataset = Dataset.from_pandas(test_df).map(\n        preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E'])\n\ntest_predictions = trainer.predict(tokenized_test_dataset).predictions\npredictions_as_ids = np.argsort(-test_predictions, 1)\npredictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\npredictions_as_string = test_df['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:42:35.055773Z","iopub.status.idle":"2023-09-02T02:42:35.056299Z","shell.execute_reply.started":"2023-09-02T02:42:35.056015Z","shell.execute_reply":"2023-09-02T02:42:35.056073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute Validation Score","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking\nimport numpy as np\ndef precision_at_k(r, k):\n    \"\"\"Precision at k\"\"\"\n    assert k <= len(r)\n    assert k != 0\n    return sum(int(x) for x in r[:k]) / k\n\ndef MAP_at_3(predictions, true_items):\n    \"\"\"Score is mean average precision at 3\"\"\"\n    U = len(predictions)\n    map_at_3 = 0.0\n    for u in range(U):\n        user_preds = predictions[u].split()\n        user_true = true_items[u]\n        user_results = [1 if item == user_true else 0 for item in user_preds]\n        for k in range(min(len(user_preds), 3)):\n            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n    return map_at_3 / U","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:42:35.05812Z","iopub.status.idle":"2023-09-02T02:42:35.059239Z","shell.execute_reply.started":"2023-09-02T02:42:35.058829Z","shell.execute_reply":"2023-09-02T02:42:35.058895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = MAP_at_3(test_df.prediction.values, test_df.answer.values)\nprint( 'CV MAP@3 =',m )","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:42:35.062122Z","iopub.status.idle":"2023-09-02T02:42:35.06267Z","shell.execute_reply.started":"2023-09-02T02:42:35.062377Z","shell.execute_reply":"2023-09-02T02:42:35.062401Z"},"trusted":true},"execution_count":null,"outputs":[]}]}